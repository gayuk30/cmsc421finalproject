{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuvRsDENUdhV",
        "outputId": "d70722d0-be84-4aa6-ddce-116621396cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.2.2)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "# Install the required libraries\n",
        "%pip install youtube-transcript-api\n",
        "%pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from getpass import getpass\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "\n",
        "api_key = getpass(\"API: \")\n",
        "openai.api_key = api_key\n",
        "\n",
        "def get_video_id(url):\n",
        "    # Extracts video ID from YouTube URL.\n",
        "    from urllib.parse import urlparse, parse_qs\n",
        "    query = urlparse(url).query\n",
        "    video_id = parse_qs(query).get('v')\n",
        "    return video_id[0] if video_id else None\n",
        "\n",
        "def fetch_transcript(video_id):\n",
        "    # Fetches the YouTube video transcript.\n",
        "    try:\n",
        "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        transcript_text = ' '.join([item['text'] for item in transcript_list])\n",
        "        return transcript_text if transcript_text else None\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Failed to fetch transcript: {e}\")\n",
        "\n",
        "def summarize_text(text):\n",
        "    # Uses OpenAI's GPT model to summarize the text.\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"Provide a comprehensive summary of this transcript.\"},\n",
        "                  {\"role\": \"user\", \"content\": text}],\n",
        "        max_tokens=600\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_url = input(\"Youtube: \")\n",
        "    video_id = get_video_id(video_url)\n",
        "    if video_id:\n",
        "        transcript = fetch_transcript(video_id)\n",
        "        if transcript:\n",
        "            print(\"Able to fetch.\")\n",
        "            summary = summarize_text(transcript)\n",
        "            print(\"Summary:\", summary)\n",
        "        else:\n",
        "            print(\"Failed to fetch.\")\n",
        "    else:\n",
        "        print(\"Invalid YouTube URL\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km8VmPP2UhOD",
        "outputId": "60f56375-ccba-4301-b341-0211a56a33b7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API: ··········\n",
            "Youtube: https://www.youtube.com/watch?v=jKyGrkEpMlM&t=3s\n",
            "Able to fetch.\n",
            "Summary: The speaker discusses the importance of Gestalt theory in art and design, emphasizing that understanding just Gestalt Theory allows one to suggest ideas without drawing them, which is key to achieving artistic mastery. They explain the elements of art and principles of design (such as line, space, color, shape, balance, contrast, movement, etc.) to provide foundational knowledge. Gestalt theory is presented as the missing context that complements the elements and principles of art, shaping how we perceive and make art. The speaker highlights key Gestalt principles like proximity, similarity, symmetry, continuation, closure, common fate, past experience, common region, and element connectedness, illustrating how these concepts impact the grouping and perception of visual elements. Examples and explanations are provided to help viewers understand how these Gestalt principles influence composition and perception in art. The speaker encourages viewers to delve deeper into elements, principles, and Gestalt theory to enhance their understanding of art and design. Towards the end, they invite viewers to join virtual art classes for further learning and development. The overall message emphasizes the importance of understanding Gestalt theory in creating effective and meaningful art pieces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3dipzGWty6o",
        "outputId": "8bd1ccf1-1d8a-4c38-a752-4a33588a0605"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IFCnDtTiirrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import requests\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search\n",
        "import numpy as np\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')  # Punkt Tokenizer Model for English.\n",
        "nltk.download('stopwords')  # Common words that generally have little lexical content.\n",
        "\n",
        "def get_search_results(word):\n",
        "    # Performs a Google search for the given word and retrieves the top 25 results,\n",
        "    # returning them as a list. Handles exceptions if the search does not yield results.\n",
        "    try:\n",
        "        search_results = search(word, num=25, stop=25, pause=2.0)\n",
        "        return list(search_results)\n",
        "    except StopIteration:\n",
        "        return []\n",
        "\n",
        "def extract_keywords(text):\n",
        "    # Tokenizes the text into words and filters out common stopwords and non-alphanumeric characters,\n",
        "    # then returns the five most common words.\n",
        "    words = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    fdist = FreqDist(filtered_words)\n",
        "    return [word for word, _ in fdist.most_common(5)]\n",
        "\n",
        "def classify_relevance(search_results, keywords):\n",
        "    # Evaluates the relevance of search results based on the occurrence of keywords in the title.\n",
        "    # Returns a list of binary values indicating relevance.\n",
        "    relevance = []\n",
        "    for result in search_results:\n",
        "        title = result.split(' - ')[0].lower()\n",
        "        is_relevant = any(keyword in title for keyword in keywords)\n",
        "        relevance.append(1 if is_relevant else 0)\n",
        "    return relevance\n",
        "\n",
        "def train_classifier(X, y):\n",
        "    # Trains a logistic regression classifier using the given data.\n",
        "    # Returns both the trained classifier and the vectorizer used for feature extraction.\n",
        "    vectorizer = CountVectorizer()\n",
        "    X_train = vectorizer.fit_transform(X)\n",
        "    clf = LogisticRegression()\n",
        "    clf.fit(X_train, y)\n",
        "    return clf, vectorizer\n",
        "\n",
        "def find_resources(text):\n",
        "    # Extracts keywords from the text, searches for related web pages, and evaluates their relevance\n",
        "    # based on the presence of keywords in the titles. Returns the most relevant results.\n",
        "    keywords = extract_keywords(text)\n",
        "    search_results = get_search_results(' '.join(keywords))\n",
        "    relevance_labels = classify_relevance(search_results, keywords)\n",
        "    X_train, _, y_train, _ = train_test_split(search_results, relevance_labels, test_size=0.2, random_state=42)\n",
        "    clf, vectorizer = train_classifier(X_train, y_train)\n",
        "    X_test = vectorizer.transform(search_results)\n",
        "    predicted_labels = clf.predict(X_test)\n",
        "    relevant_results = [result for result, label in zip(search_results, predicted_labels) if label == 1]\n",
        "    return relevant_results\n",
        "\n",
        "# Find relevant resources\n",
        "relevant_resources = find_resources(summary)\n",
        "print(\"Relevant resources:\")\n",
        "for resource in relevant_resources:\n",
        "    print(resource)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W56m8vhVuiDZ",
        "outputId": "17c9879e-2051-4408-d85b-70f9d3081a53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevant resources:\n",
            "https://www.toptal.com/designers/ui/gestalt-principles-of-design\n",
            "https://www.painting-course.com/the-painting-course-1/lesson-20-gestalt-principles-of-art-and-design\n",
            "https://www.interaction-design.org/literature/topics/gestalt-principles\n",
            "https://www.interaction-design.org/literature/topics/gestalt-principles#what_are_the_gestalt_principles?-0\n",
            "https://www.interaction-design.org/literature/topics/gestalt-principles#gestalt_principles_%E2%80%93_a_background-1\n",
            "https://www.interaction-design.org/literature/topics/gestalt-principles#gestalt_principles-2\n",
            "https://webflow.com/blog/gestalt-principles-of-design\n",
            "https://graybox.co/knowledge/blog/gestalt-principles-applied-to-design\n",
            "https://picsart.com/blog/post/gestalt-principles-for-design\n",
            "https://www.shutterstock.com/blog/gestalt-theory-in-design\n",
            "https://in.indeed.com/career-advice/career-development/gestalt-principles\n",
            "https://www.usertesting.com/blog/gestalt-principles\n",
            "https://www.superside.com/blog/gestalt-principles-of-design\n",
            "https://medium.com/@mail2jackey/mastering-the-art-of-visual-language-the-power-of-gestalt-principles-in-design-9ffd568cedb1\n",
            "https://www.manypixels.co/blog/graphic-design/gestalt-principles\n",
            "https://www.sartle.com/blog/post/art-history-reader-gestalt-theory\n",
            "https://bootcamp.uxdesign.cc/understanding-elements-of-design-with-gestalt-principles-b6e37354847e\n",
            "https://zight.com/blog/how-to-use-gestalt-principle-in-design/\n",
            "https://www.coreldraw.com/en/tips/gestalt-principles/\n",
            "https://thedecisionlab.com/reference-guide/psychology/gestalt-principles\n",
            "https://venngage.com/blog/gestalt-principles/\n",
            "https://dodonut.com/blog/gestalt-principles-of-design/\n",
            "https://dovetail.com/ux/gestalt-principles/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "\n",
        "tokens = word_tokenize(transcript)\n",
        "common_words = set(stopwords.words('english'))\n",
        "filtered = [word for word in tokens if word.lower() not in common_words]\n",
        "filtered = [word for word in filtered if word not in punctuation]\n",
        "filtered_text = ' '.join(filtered)\n",
        "print(filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH188Uwt8MLq",
        "outputId": "1f58aba4-e622-4dff-f228-af15f9d1041c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gestalt theory important ask well know Gestalt Theory 'll able suggest ideas without drawing yes friends secret sauce artistic mastery nine first though let 's talk elements principles want go case elements art seven line space color shape one form texture value seven elements art principles design 's eight technically there's ten combined four balance contrast movement rhythm repetition emphasis unity variety unity grouped harmony proportions n't remember elements art principles design entire playlist explain detail try funny 'll link description watch next principles design principles design stuff make artwork feel better think elements like nouns 're nouns artwork right 's objects things think principles adjectives adjectives verbs right 's things make nouns move makes work makes interesting know elements art know principles design know 's third one Gestalt theory weird one elements art nouns principles design adjectives verbs Gestalt theory context sentence say sentence whenever heck want many nouns verbs adjectives want however nouns adjectives n't context behind sentence still feels meaningless Gestalt theory context behind Gestalt theory utilize elements principles art make sense within human perception 's perceive things make art make sense funny thing Gestalt theory absolutely know almost every single bit Gestalt Theory 's we're putting definitions learned Gestalt theory first time like 've never heard Gestalt theory life every single piece Gestalt Theory like oh yeah figured n't know name right that's kind Gestalt theory feels learn first time let 's talk Gestalt Theory 's bunch 'm going go ones think relevant first one proximity things closer together seen group 've got one little huddling together bunch beans one side we've got another little huddling together another group beans another side bean group feels like one group groups feels like another group even draw bunch different shapes say threw squares right right got bunch squares maybe stars know whatever deal maybe 's spirals triangle two 're different elements proximity see one one group see one another group 's kind think proximity second thingy similarity things similar grouped regardless proximity we've got whole sea like blue dots let 's say got bunch little blue dots two red dots one 's red one 's red 're close automatically brains like oh yeah two red dots grouped together 're similar therefore within group kind toss colors tossed couple green dots got one one see green dots another group regardless close together kind toss another one feels unbalanced group side 've got put another one regardless things similar one another grouped regardless proximity even 're far away 've got sea stuff 's really similar 've got like two little dots sides feel bit strange 's similarity next symmetry order one requires little bit bit explanation symmetry order creates consistency stability structure even numbers equal symmetry odd numbers equal asymmetry use discretion think composition amount objects see within composition let 's think numbers four numbers five first four dots kind like perfectly symmetrical way think like oh yeah four equals symmetry say half composition two dots half two dots right creates sense symmetry odd numbers number five creates bit asymmetry focal point like split perfect tabs without cutting one elements half cut half creates number six want something stronger focal point better use asymmetry using even numbers tends create much symmetry create monotony 's usually better asymmetry within works especially comes composition next thing 're continuation elements move eyes across across comp 'm going say comp 's short composition deals leading lines movement add focal points envision spiral start one end spiral 'll slowly spiraled towards center 's continuation eyes continue spiral get center whatever little focal point another easy way continuation little focal point got bunch arrows arrows brain automatically continues arrows go towards wherever 're pointing right spiral one bit fun though yeah continuation elements move eyes across composition allow create movement continuation context movement lot times need continuation order movement work leading lines kind deal closure one 's favorite one closure idea brains finish incomplete shape using context clues right brain automatically complete shapes given enough context right let draw little picture little straws 'd like support channel creation free arts education become member patreon cool okay draw suit still kind know 's tell action asked action right would tell 's saying hello waving 's waving right arms bent right one 's probably straight well kind anvision right n't completed n't completed illustration kind know that's closure idea finish stuff even without giving full context next one 's also kind fun next one called common fate sounds like final final move RPG right things moving direction automatically feel grouped together one overrides proximity right best way describe think birds right 'm gon na actually draw birds 'm gon na draw like less signs think birds know kind go one direction birds kind make v formation automatically feel grouped together somehow bunch birds around going opposite direction birds going opposite direction despite group feel grouped together 're going direction guys close together also going direction regardless though birds going birds quote unquote going opposite direction also feel grouped going wait kind helps like 've seen like really traditional paintings like like Noah 's Ark right animals kind go onto ark whatever everything goes along path despite different feel grouped together common fate past experience based previous knowledge brain complete images read read used um yes hello read read 're given first last letter every single word letters inside know enough still read sentence sentence filling blanks based know similar closure one 's bit slightly different 's already understand known based experience common region elements grouped together within comfined area right one overrides every single group instruction every single one nothing common region take bunch bunch little dots let 's draw bunch dots first took squares sprinkled let 's pretend squares perfectly fine 're terrible looking unless got triangles filling rest space random random human brain go right placing bunch random shapes around went like section shapes feels grouped compared everything else feels ISO related rest shapes drawn common region 're using common regions within singular point strategy use lot compositionally common region strongest grouping one right last one last one element connectedness items connected line elements grouped right things connected line grouped 's example 's less like shapey abstract say like draw house straw house beautiful house wow 've got like got like big dinosaur 've got dinosaur maybe 's tree there's somebody flipping 's dinosaur front yard 's car somewhere weakness vehicle shows anyway got objects n't really make lot sense right 100 connected real way let throw horizon line feels like 're within space line creates element connectedness feels though 're within confined space right element connectedness maybe 'll bushes back also helps elements feel connected helps create scene element connectedness create scenes way items connected line elements grouped join virtual class learn live professional artists get creative assignments individual guidance real-time feedback artwork start today level practice made far theory without getting bored congratulations 're official art nerd like students Winged Campus go watch elements principles videos linked learned something new like share fellow art nerd love receiving quality free arts education subscribe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Each word gets counted for frequency\n",
        "word_frequency = Counter(filtered)\n",
        "\n",
        "# Get the 25 most common words\n",
        "mcw = word_frequency.most_common(25)\n",
        "\n",
        "for t in mcw:\n",
        "    word, frequency = t\n",
        "    # Contractions that show up in word count\n",
        "    if word in [\"’\", \"'s\", '``', \"n't\", \"''\", \"'re\"]:\n",
        "        mcw.remove(t)\n",
        "\n",
        "print(\"5 Most Common Words:\")\n",
        "for word, frequency in mcw:\n",
        "    print(f\"{word}: {frequency}\")\n",
        "\n",
        "#Words are the manually picked out based on if they are still too general or not; top 5 are chosen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US29a-mt9qay",
        "outputId": "572b409f-b301-455f-8e17-6314131fa7ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 Most Common Words:\n",
            "one: 34\n",
            "like: 26\n",
            "right: 23\n",
            "elements: 17\n",
            "got: 15\n",
            "grouped: 14\n",
            "kind: 14\n",
            "Gestalt: 13\n",
            "know: 12\n",
            "group: 12\n",
            "dots: 12\n",
            "bunch: 11\n",
            "together: 11\n",
            "theory: 10\n",
            "principles: 10\n",
            "little: 10\n",
            "another: 10\n",
            "art: 9\n",
            "think: 9\n",
            "feels: 9\n",
            "going: 9\n",
            "let: 8\n",
            "feel: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Actual most common keywords for each video\n",
        "actual_keywords = [\n",
        "    {'lincoln', 'south', 'mcclellen', 'north', 'slavery'},\n",
        "    {'true', 'statement', 'statements', 'mathematical', 'gödel'},\n",
        "    {'electricity', 'power', 'current', 'electric', 'electrons'},\n",
        "    {'nietzsche', 'life', 'suffering', 'philosophy', 'power'},\n",
        "    {'elements', 'grouped', 'gestalt', 'theory', 'principles'}\n",
        "]\n",
        "\n",
        "# Sets of keywords generated from summaries for each trial (3x each for each 5 videos)\n",
        "generated_keywords = [\n",
        "    [\n",
        "        {'war', 'video', 'slavery', 'lincoln', 'abraham'},\n",
        "        {'video', 'lincoln', 'slavery', 'war', 'battle'},\n",
        "        {'war', 'lincoln', 'video', 'american', 'slavery'}\n",
        "    ],\n",
        "    [\n",
        "        {'mathematical', 'gödel', 'statements', 'statement', 'unprovable'},\n",
        "        {'gödel', 'mathematical', 'theorem', 'statements', 'statement'},\n",
        "        {'statements', 'mathematical', 'gödel', 'unprovable', 'statement'}\n",
        "    ],\n",
        "    [\n",
        "        {'electricity', 'power', 'electric', 'plants', 'like'},\n",
        "        {'electricity', 'power', 'plants', 'current', 'video'},\n",
        "        {'electricity', 'power', 'plants', 'electric', 'electrons'}\n",
        "    ],\n",
        "    [\n",
        "        {'nietzsche', 'personal', 'philosophy', 'work', 'modern'},\n",
        "        {'nietzsche', 'philosophy', 'personal', 'life', 'suffering'},\n",
        "        {'nietzsche', 'personal', 'modern', 'traditional', 'faith'}\n",
        "    ],\n",
        "    [\n",
        "        {'elements', 'gestalt', 'theory', 'create', 'principles'},\n",
        "        {'elements', 'principles', 'sense', 'visual', 'perceived'},\n",
        "        {'elements', 'gestalt', 'dots', 'theory', 'principles'}\n",
        "\n",
        "    ]\n",
        "]\n",
        "\n",
        "def euclidean_distance(set1, set2, all_keywords):\n",
        "    # Sets to vectors\n",
        "    v1 = np.array([1 if keyword in set1 else 0 for keyword in all_keywords])\n",
        "    v2 = np.array([1 if keyword in set2 else 0 for keyword in all_keywords])\n",
        "\n",
        "    # Calculate Euclidean between actual and generated keywords\n",
        "    distance = np.linalg.norm(v1 - v2)\n",
        "    return distance\n",
        "\n",
        "# Calculate the maximum possible Euclidean distance (when all keywords are different)\n",
        "max_distance = len(set.union(*actual_keywords)) ** 0.5\n",
        "\n",
        "# All unique keywords across all trials\n",
        "all_keywords = set.union(*actual_keywords)\n",
        "\n",
        "# Calculate the Euclidean distance between generated keywords and the actual keywords for each trial\n",
        "total = 0\n",
        "for i, j in enumerate(generated_keywords):\n",
        "    distances = [euclidean_distance(set(keywords), actual_keywords[i], all_keywords) for keywords in j]\n",
        "\n",
        "    # Normalizing by converting Euclidean distances to percentages from max_distance\n",
        "    percentages = [(1 - d / max_distance) * 100 for d in distances]\n",
        "\n",
        "    print(\"Trial\", i+1, \"Percentages:\", percentages)\n",
        "    print(\"Average Percentage Similarity for Trial\", i+1, \":\", sum(percentages) / len(percentages))\n",
        "    total += sum(percentages) / len(percentages)\n",
        "\n",
        "print(\"Average Percentage Similarity across all trials:\", total/5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_NasNnKySrr",
        "outputId": "d2c4e07c-0304-4361-95a2-db3d19f272ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 Percentages: [64.64466094067262, 64.64466094067262, 64.64466094067262]\n",
            "Average Percentage Similarity for Trial 1 : 64.64466094067262\n",
            "Trial 2 Percentages: [79.58758547680685, 79.58758547680685, 79.58758547680685]\n",
            "Average Percentage Similarity for Trial 2 : 79.58758547680685\n",
            "Trial 3 Percentages: [71.13248654051871, 71.13248654051871, 79.58758547680685]\n",
            "Average Percentage Similarity for Trial 3 : 73.95085285261476\n",
            "Trial 4 Percentages: [64.64466094067262, 79.58758547680685, 59.17517095361369]\n",
            "Average Percentage Similarity for Trial 4 : 67.80247245703106\n",
            "Trial 5 Percentages: [79.58758547680685, 64.64466094067262, 71.13248654051871]\n",
            "Average Percentage Similarity for Trial 5 : 71.78824431933272\n",
            "Average Percentage Similarity across all trials: 71.5547632092916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Calculate Cosine Similarity between actual and generated keywords\n",
        "# Did this 3x per each 5 videos\n",
        "def calculate_similarity(transcript, summary):\n",
        "    v = CountVectorizer().fit([transcript, summary])\n",
        "    vectors = v.transform([transcript, summary]).toarray()\n",
        "    similarity = cosine_similarity(vectors)\n",
        "    return similarity[0, 1]  # Similarity between transcript and summary\n",
        "\n",
        "\n",
        "similarity = calculate_similarity(transcript, summary)\n",
        "print(\"Cosine Similarity:\", similarity)\n",
        "\n",
        "# Results from each video\n",
        "#The paradox at the heart of mathematics: Gödel's Incompleteness Theorem - Marcus du Sautoy: 0.7180296285070443, 0.6728328781718516, 0.7338418450881288\n",
        "#The American Civil War - OverSimplified (Part 1): 0.807358649078939, 0.8015141569751579, 0.8139546614076966\n",
        "#How It's Made: Chocolate: 0.8498555587739476, 0.8386061761006591, 0.8477837984991412\n",
        "#Becoming Who You Really Are - The Philosophy of Friedrich Nietzsche: 0.8849369398566, 0.8439721404374021, 0.8187018680276592\n",
        "#GESTALT Theory in Art: The Power of Suggestion!: 0.5801535627075831, 0.5553691344949546, 0.6019762112438968"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu6Tc1EQjfNH",
        "outputId": "683416ca-aa5e-4310-ef59-accf8c8afc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.6019762112438968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Results from above\n",
        "cos_sim = [\n",
        "    [0.7180296285070443, 0.6728328781718516, 0.7338418450881288],\n",
        "    [0.807358649078939, 0.8015141569751579, 0.8139546614076966],\n",
        "    [0.8498555587739476, 0.8386061761006591, 0.8477837984991412],\n",
        "    [0.8849369398566, 0.8439721404374021, 0.8187018680276592],\n",
        "    [0.5801535627075831, 0.5553691344949546, 0.6019762112438968]\n",
        "]\n",
        "\n",
        "# Average the Cosine Similarities\n",
        "total = 0\n",
        "for i in cos_sim:\n",
        "  vid_sum = 0\n",
        "  for j in i:\n",
        "    vid_sum += j\n",
        "  total += (vid_sum/3)\n",
        "  print(vid_sum/3)\n",
        "print(\"total accuracy: \", (total/5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qd-GauEsekN",
        "outputId": "1adf88b2-0665-43d8-edd3-c708f3caa849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7082347839223416\n",
            "0.8076091558205979\n",
            "0.8454151777912493\n",
            "0.8492036494405538\n",
            "0.5791663028154782\n",
            "total accuracy:  0.7579258139580443\n"
          ]
        }
      ]
    }
  ]
}